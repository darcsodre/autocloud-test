{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este código implementa o algoritmo AutoCloud, uma abordagem baseada em aprendizado não supervisionado para a detecção de padrões e agrupamento de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BBCVTvDfH1c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from plotly.subplots import make_subplots\n",
        "from plotly.offline import plot\n",
        "import plotly.graph_objects as go\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VyEywC73IO5"
      },
      "outputs": [],
      "source": [
        "listaCor =np.array(['#4C72B0','#DD8452','#55A868','#C44E52','#8172B3','#937860','#DA8BC3','#8C8C8C','#CCB974','#64B5CD'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZJVjEFmfH1h"
      },
      "outputs": [],
      "source": [
        "class DataCloud:\n",
        "\tN=0 #Conta o número total de nuvens de dados criadas.\n",
        "\tdef __init__(self,x): #É chamado quando uma nova instância de DataCloud é criada.\n",
        "\t\tself.n=1 #Inicializa o n de pontos na nuvem como 1, pois estamos adicionando o primeiro ponto x.\n",
        "\t\tself.mean=x #Inicializa a média da nuvem como o valor do primeiro ponto x. A média é o centro da nuvem.\n",
        "\t\tself.variance=0 #Inicializa a variância como 0, pois com apenas um ponto, não há dispersão.\n",
        "\t\tself.pertinency=1 #Inicializa o grau de pertinência como 1, indicando que o ponto pertence completamente à nuvem.\n",
        "\t\tDataCloud.N+=1 #Incrementa o contador de nuvens de dados criadas.\n",
        "\tdef addDataClaud(self,x):\n",
        "\t\tself.n=2 #Define o n de pontos na nuvem como 2, assumindo que estamos adicionando um segundo ponto\n",
        "\t\tself.mean=(self.mean+x)/2 #Atualiza a média da nuvem. A nova média é a média aritmética entre a média anterior e o novo ponto x.\n",
        "\t\tself.variance=((np.linalg.norm(self.mean-x))**2) #Atualiza a variância da nuvem. A variância é calculada como o quadrado da distância entre a nova média e o novo ponto x.\n",
        "\tdef updateDataCloud(self,n,mean,variance): #Este método atualiza os atributos da nuvem de dados com novos valores.\n",
        "\t\tself.n=n #Atualiza o número de pontos na nuvem.\n",
        "\t\tself.mean=mean #Atualiza a média da nuvem.\n",
        "\t\tself.variance=variance #Atualiza a variância da nuvem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqqyO6VBfH1m"
      },
      "outputs": [],
      "source": [
        "class AutoCloud:\n",
        "\tc= np.array([DataCloud(0)],dtype=DataCloud)\n",
        "\talfa= np.array([0.0],dtype=float)\n",
        "\tintersection = np.zeros((1,1),dtype=int)\n",
        "\tlistIntersection = np.zeros((1),dtype=int)\n",
        "\tmatrixIntersection = np.zeros((1,1),dtype=int)\n",
        "\trelevanceList = np.zeros((1),dtype=int)\n",
        "\tk=1\n",
        "\tdef __init__(self, m):\n",
        "\t\tAutoCloud.m = m\n",
        "\t\tAutoCloud.c= np.array([DataCloud(0)],dtype=DataCloud)\n",
        "\t\tAutoCloud.alfa= np.array([0.0],dtype=float)\n",
        "\t\tAutoCloud.intersection = np.zeros((1,1),dtype=int)\n",
        "\t\tAutoCloud.listIntersection = np.zeros((1),dtype=int)\n",
        "\t\tAutoCloud.relevanceList = np.zeros((1),dtype=int)\n",
        "\t\tAutoCloud.matrixIntersection = np.zeros((1,1),dtype=int)\n",
        "\t\tAutoCloud.classIndex = []\n",
        "\t\tAutoCloud.k = 1\n",
        "\n",
        "\tdef mergeClouds(self):\n",
        "\t\ti=0\n",
        "\t\twhile(i<len(AutoCloud.listIntersection)-1):\n",
        "\t\t\tmerge=False\n",
        "\t\t\tj=i+1\n",
        "\t\t\twhile(j<len(AutoCloud.listIntersection)):\n",
        "\t\t\t\t#print(\"i\",i,\"j\",j,\"l\",np.size(AutoCloud.listIntersection),\"m\",np.size(AutoCloud.matrixIntersection),\"c\",np.size(AutoCloud.c))\n",
        "\t\t\t\tif(AutoCloud.listIntersection[i] == 1 and AutoCloud.listIntersection[j] == 1):\n",
        "\t\t\t\t\tAutoCloud.matrixIntersection[i,j] = AutoCloud.matrixIntersection[i,j] + 1;\n",
        "\t\t\t\tnI = AutoCloud.c[i].n\n",
        "\t\t\t\tnJ = AutoCloud.c[j].n\n",
        "\t\t\t\tmeanI = AutoCloud.c[i].mean\n",
        "\t\t\t\tmeanJ = AutoCloud.c[j].mean\n",
        "\t\t\t\tvarianceI = AutoCloud.c[i].variance\n",
        "\t\t\t\tvarianceJ = AutoCloud.c[j].variance\n",
        "\t\t\t\tnIntersc = AutoCloud.matrixIntersection[i,j]\n",
        "\t\t\t\tif (nIntersc > (nI - nIntersc) or nIntersc > (nJ - nIntersc)):\n",
        "\t\t\t\t\tprint(f'na iteracao {self.k} houve fusao de clouds')\n",
        "\t\t\t\t\tmerge = True\n",
        "\t\t\t\t\t#update values\n",
        "\t\t\t\t\tn = nI + nJ - nIntersc\n",
        "\t\t\t\t\tmean = ((nI * meanI) + (nJ * meanJ))/(nI + nJ)\n",
        "\t\t\t\t\tvariance = ((nI - 1) * varianceI + (nJ - 1) * varianceJ)/(nI + nJ - 2)\n",
        "\t\t\t\t\tnewCloud = DataCloud(mean)\n",
        "\t\t\t\t\tnewCloud.updateDataCloud(n,mean,variance)\n",
        "\t\t\t\t\t#atualizando lista de interseção\n",
        "\t\t\t\t\tAutoCloud.listIntersection = np.concatenate((AutoCloud.listIntersection[0 : i], np.array([1]), AutoCloud.listIntersection[i + 1 : j],AutoCloud.listIntersection[j + 1 : np.size(AutoCloud.listIntersection)]),axis=None)\n",
        "\t\t\t\t\t#atualizando lista de data clouds\n",
        "\t\t\t\t\tAutoCloud.c = np.concatenate((AutoCloud.c[0 : i ], np.array([newCloud]), AutoCloud.c[i + 1 : j],AutoCloud.c[j + 1 : np.size(AutoCloud.c)]),axis=None)\n",
        "\t\t\t\t\t#update  intersection matrix\n",
        "\t\t\t\t\tM0 = AutoCloud.matrixIntersection\n",
        "\t\t\t\t\t#Remover linhas\n",
        "\t\t\t\t\tM1=np.concatenate((M0[0 : i , :],np.zeros((1,len(M0))),M0[i + 1 : j, :],M0[j + 1 : len(M0), :]))\n",
        "\t\t\t\t\t#remover colunas\n",
        "\t\t\t\t\tM1=np.concatenate((M1[:, 0 : i ],np.zeros((len(M1),1)),M1[:, i+1 : j],M1[:, j+1 : len(M0)]),axis=1)\n",
        "\t\t\t\t\t#calculando nova coluna\n",
        "\t\t\t\t\tcol = (M0[:, i] + M0[:, j])*(M0[: , i]*M0[:, j] != 0)\n",
        "\t\t\t\t\tcol = np.concatenate((col[0 : j], col[j + 1 : np.size(col)]))\n",
        "\t\t\t\t\t#calculando nova linha\n",
        "\t\t\t\t\tlin = (M0[i, :]+M0[j, :])*(M0[i, :]*M0[j, :] != 0)\n",
        "\t\t\t\t\tlin = np.concatenate((lin[ 0 : j], lin[j + 1 : np.size(lin)]))\n",
        "\t\t\t\t\t#atualizando coluna\n",
        "\t\t\t\t\tM1[:,i]=col\n",
        "\t\t\t\t\t#atualizando linha\n",
        "\t\t\t\t\tM1[i,:]=lin\n",
        "\t\t\t\t\tM1[i, i + 1 : j] = M0[i, i + 1 : j] + M0[i + 1 : j, j].T;\n",
        "\t\t\t\t\tAutoCloud.matrixIntersection = M1\n",
        "\t\t\t\tj += 1\n",
        "\t\t\tif(merge):\n",
        "\t\t\t\ti = 0\n",
        "\t\t\telse:\n",
        "\t\t\t\ti += 1\n",
        "\n",
        "\tdef run(self,X):\n",
        "\t\tAutoCloud.listIntersection = np.zeros((np.size(AutoCloud.c)),dtype=int)\n",
        "\t\tif AutoCloud.k==1:\n",
        "\t\t\tAutoCloud.c[0]=DataCloud(X)\n",
        "\t\t\tAutoCloud.classIndex.append(0)\n",
        "\t\telif AutoCloud.k==2:\n",
        "\t\t\tAutoCloud.c[0].addDataClaud(X)\n",
        "\t\t\tAutoCloud.classIndex.append(0)\n",
        "\t\telif AutoCloud.k>=3:\n",
        "\t\t\ti=0\n",
        "\t\t\tcreateCloud = True\n",
        "\t\t\tAutoCloud.alfa = np.zeros((np.size(AutoCloud.c)),dtype=float)\n",
        "\t\t\tfor data in AutoCloud.c:\n",
        "\t\t\t\tn= data.n +1\n",
        "\t\t\t\tmean = ((n-1)/n)*data.mean + (1/n)*X\n",
        "\t\t\t\tvariance = ((n-1)/n)*data.variance +(1/n)*((np.linalg.norm(X-mean))**2)\n",
        "\t\t\t\tif variance == 0:\n",
        "\t\t\t\t\teccentricity = 0\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\teccentricity = (1/n)+((mean-X).T.dot(mean-X))/(n*variance)\n",
        "\t\t\t\ttypicality = 1 - eccentricity\n",
        "\t\t\t\tnorm_eccentricity = eccentricity/2\n",
        "\t\t\t\tnorm_typicality = typicality/(AutoCloud.k-2)\n",
        "\t\t\t\tdata.eccAn = eccentricity\n",
        "\t\t\t\t#print('tiṕicidade normalizada',norm_typicality)\n",
        "\t\t\t\tif(norm_eccentricity<=(AutoCloud.m**2 +1)/(2*n)):\n",
        "\t\t\t\t\t#print('dentro do limiar. tipicidade normalizada:',norm_typicality)\n",
        "\t\t\t\t\tdata.updateDataCloud(n,mean,variance)\n",
        "\t\t\t\t\tAutoCloud.alfa[i] = norm_typicality\n",
        "\t\t\t\t\tcreateCloud= False\n",
        "\t\t\t\t\tAutoCloud.listIntersection[i] = 1\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tAutoCloud.alfa[i] = 0\n",
        "\t\t\t\t\tAutoCloud.listIntersection[i] = 0\n",
        "\t\t\t\ti+=1\n",
        "\t\t\t\t\n",
        "\t\t\tif(createCloud):\n",
        "\t\t\t\tAutoCloud.c = np.append(AutoCloud.c,DataCloud(X))\n",
        "\t\t\t\tAutoCloud.listIntersection = np.insert(AutoCloud.listIntersection,i,1)\n",
        "\t\t\t\tAutoCloud.matrixIntersection = np.pad(AutoCloud.matrixIntersection, ((0,1),(0,1)), 'constant', constant_values=(0))\n",
        "\t\t\tself.mergeClouds()\n",
        "\t\t\t#print('AutoCloud.alfa:', AutoCloud.alfa)\n",
        "\t\t\tif np.sum(AutoCloud.alfa) >0:\n",
        "\t\t\t\tAutoCloud.relevanceList = AutoCloud.alfa /np.sum(AutoCloud.alfa)\n",
        "\t\t\tif np.sum(AutoCloud.alfa) == 0:\n",
        "\t\t\t\tAutoCloud.relevanceList = AutoCloud.alfa /np.inf\n",
        "\t\t\tclassIndex = np.argmax(AutoCloud.relevanceList)\n",
        "\t\t\tAutoCloud.classIndex.append(classIndex)\n",
        "\n",
        "\n",
        "\t\tAutoCloud.k=AutoCloud.k+1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4gc7EZXfH1r"
      },
      "source": [
        "#Carregamento e Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "df = pd.read_csv('[coleta 2] captura_pacotes.csv', sep=',') #Selecionar colunas relevantes\n",
        "df_reduzido = df.iloc[::4, :] #Selecionar apenas uma a cada quatro amostras\n",
        "df_reduzido = df_reduzido.fillna(0) #Substituir valores NaN por zero em todo o dataframe\n",
        "#print(df.head())\n",
        "\n",
        "f1 = df_reduzido['TCP Len'].values\n",
        "f2 = df_reduzido['MQTT Len'].values\n",
        "f3 = df_reduzido['TCP Time Delta'].values\n",
        "\n",
        "df2= pd.DataFrame(np.array([f1,f2,f3])).T\n",
        "dados = np.array([f1,f2,f3]).T\n",
        "print(df2)\n",
        "#print(\"Forma original:\", dados.shape)\n",
        "#print(\"Forma transposta:\", dados.T.shape)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv('[coleta 2] captura_pacotes.csv', sep=',')\n",
        "df = df.fillna(0) #Substituir valores NaN por zero em todo o dataframe\n",
        "#print(df.head())\n",
        "f1 = df['TCP Len'].values\n",
        "f2 = df['MQTT Len'].values\n",
        "f3 = df['TCP Time Delta'].values\n",
        "\n",
        "df2= pd.DataFrame(np.array([f1,f2,f3])).T\n",
        "dados = np.array([f1,f2,f3]).T\n",
        "print(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Teste de verificação das cloud, processa uma amostra por vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2.isnull().sum()  # Contar valores ausentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "i = 0\n",
        "teste=AutoCloud(2)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "print('iteration:',i+1,'x:',dados[i])\n",
        "teste.run(np.array(dados[i]))\n",
        "i = i + 1\n",
        "print('----------------------------------')\n",
        "for j,cloud in enumerate(teste.c,start=0): \n",
        "    print(f'cloud numero {j+1}') \n",
        "    print('n:',cloud.n,'mean:',cloud.mean,'variance:',cloud.variance)\n",
        "    print('+++++++++++++++++++++++++++++++')\n",
        "\n",
        "#j é o índice da nuvem dentro do conjunto de nuvens teste.c, e ele é usado para identificar qual nuvem está sendo processada no momento.'\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Teste do parâmetro m, que define a tolerância para a criação de novas nuvens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Gráfico para vsualizar o comporatmento de diferentes valores de m.\n",
        "x = np.arange(1,100) #altera os valores de amostras \n",
        "def limiar(m,x):\n",
        "    return (1+m**2)/(2*x)\n",
        "ms = np.array([1.25,1.5,2])\n",
        "labels = [f'm:{ms[i-1]}' for i in range(1,1+len(ms))]\n",
        "'''plt.figure(figsize=(10,5))\n",
        "for m,label in zip(ms,labels):\n",
        "    plt.plot(x,limiar(m,x),label=label)\n",
        "xticks = list(np.arange(0,31))\n",
        "yticks = list(np.arange(0,1.75,0.125))\n",
        "plt.xticks(xticks)\n",
        "plt.yticks(yticks)\n",
        "plt.xlabel('quantidade de dados')\n",
        "plt.ylabel('valores de m')\n",
        "plt.grid(True)\n",
        "plt.legend()'''\n",
        "\n",
        "fig = make_subplots(rows=1, cols=1)\n",
        "for m,label in zip(ms[:],labels[:]):\n",
        "    fig.add_trace(go.Scatter(x=x,y=limiar(m,x),name=label),row=1,col=1)\n",
        "fig.update_layout(width=800, height=500, title=f'análise dos valores de m')\n",
        "fig.update_yaxes(title_text = f'valor de m{m}')\n",
        "fig.update_xaxes(title_text = 'quatidade de dados')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "teste=AutoCloud(2.0) # valor do parametro m\n",
        "j=25  #Define que apenas as primeiras 25 amostras serão usadas\n",
        "for dado in dados[:j]:\n",
        "    teste.run(np.array(dado))\n",
        "print('--------------------------------')\n",
        "for k,cloud in enumerate(teste.c,start=0):\n",
        "    print(f'cloud numero {k+1}')\n",
        "    print('n:',cloud.n,'mean:',cloud.mean,'variance:',cloud.variance)\n",
        "    print('+++++++++++++++++++++++++++++++')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dados= dados.T\n",
        "teste=AutoCloud(1.5)\n",
        "for t in dados:\n",
        "    teste.run(np.array(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar figura e eixos 3D\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "j=100 #Define a quantidade de amostras serão usadas\n",
        "# Plotar os pontos\n",
        "\n",
        "for cloud in teste.c:\n",
        "    m = cloud.mean\n",
        "    ax.scatter(m[0], m[1], m[2],  marker='o', s=40, label='centroide')\n",
        "ax.scatter(f1[0:j], f2[0:j], f3[0:j], c='red', marker='+', s=20, label='Pontos')\n",
        "\n",
        "# Rótulos dos eixos\n",
        "ax.set_xlabel('Eixo f1')\n",
        "ax.set_ylabel('Eixo f2')\n",
        "ax.set_zlabel('Eixo f3')\n",
        "\n",
        "# Título e legenda\n",
        "ax.set_title('Gráfico de Pontos 3D')\n",
        "#ax.legend('upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "j=25 #Define a quantidade de amostras serão usadas\n",
        "f = np.array([f1[:j],f2[:j],f3[:j]]).T\n",
        "df_teste = pd.DataFrame(f)\n",
        "df_teste.columns = ['f1','f2','f3',]\n",
        "print(df_teste)\n",
        "plt.scatter(f1[:j],f2[:j])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Processa todas as amostras para o conjunto completo de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "dados= dados.T\n",
        "teste=AutoCloud(2)\n",
        "for t in dados:\n",
        "    teste.run(np.array(t))]''\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
