{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo a seguir fornece uma implementação para monitorar a entropia de Shannon de flags TCP em um fluxo de dados (data stream) em tempo real. Usando dataset rotulado com 5 flgs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt  # Importar matplotlib para criar gráficos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular entropia de Shannon\n",
    "def calcular_entropia(series):\n",
    "    \"\"\"Calcula a entropia de Shannon para uma série categórica.\"\"\"\n",
    "    counts = series.value_counts(normalize=True)  # Obter distribuição de probabilidades\n",
    "    entropy = -np.sum(counts * np.log2(counts + 1e-10))  # Aplicar fórmula de Shannon\n",
    "    return entropy\n",
    "\n",
    "'''\n",
    "def analisar_distribuicao(series):\n",
    "    \"\"\"\n",
    "    Analisa a distribuição de uma série categórica.\n",
    "    Imprime e retorna o total de amostras, os valores únicos e a contagem de cada valor único.\n",
    "    \"\"\"\n",
    "    # Total de amostras\n",
    "    total_amostras = len(series)\n",
    "    \n",
    "    # Valores únicos e suas contagens\n",
    "    contagens = series.value_counts()\n",
    "    valores_unicos = contagens.index.tolist()\n",
    "    repeticoes = contagens.values.tolist()\n",
    "    \n",
    "    # Imprimir informações\n",
    "    print(f\"Total de amostras: {total_amostras}\")\n",
    "    print(f\"Valores únicos: {valores_unicos}\")\n",
    "    print(f\"Repetições: {repeticoes}\")\n",
    "    \n",
    "    # Retornar resultados (opcional, caso você ainda precise dos dados)\n",
    "    return {\n",
    "        \"total_amostras\": total_amostras,\n",
    "        \"valores_unicos\": valores_unicos,\n",
    "        \"repeticoes\": repeticoes\n",
    "    }'''\n",
    "\n",
    "# Classe para monitoramento da entropia em tempo real (Data Stream)\n",
    "class EntropyMonitor:\n",
    "    def __init__(self, flags, window_size=100):\n",
    "        self.flags = flags  # Nomes das colunas (flags TCP)\n",
    "        self.window_size = window_size  # Tamanho da janela deslizante\n",
    "        self.stream_data = deque(maxlen=window_size)  # Estrutura para armazenar dados\n",
    "\n",
    "    def update_stream(self, new_data):\n",
    "        \"\"\"Atualiza a janela de dados com novas observações.\"\"\"\n",
    "        self.stream_data.append(new_data)\n",
    "\n",
    "    def calculate_entropy(self):\n",
    "        \"\"\"Calcula a entropia das flags TCP dentro da janela de observação.\"\"\"\n",
    "        if len(self.stream_data) < 2:  # Evita cálculo com poucos dados\n",
    "            return {flag: 0 for flag in self.flags}\n",
    "        \n",
    "        # Criar DataFrame da janela atual\n",
    "        stream_df = pd.DataFrame(list(self.stream_data), columns=self.flags)\n",
    "        \n",
    "        # Calcular entropia das flags\n",
    "        entropia_flags = {flag: calcular_entropia(stream_df[flag]) for flag in self.flags}\n",
    "        return entropia_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando monitoramento de entropia com resets entre as partes...\n",
      "\n",
      "\n",
      "Monitoramento finalizado com resets nas transições entre partes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Carregar CSV\n",
    "df = pd.read_csv('dataset_legitimo_malicioso.csv', sep=',')\n",
    "\n",
    "# Selecionar colunas relevantes\n",
    "flags = ['tcp.flags.ack', 'tcp.flags.syn', 'tcp.flags.fin']\n",
    "df2 = df[['frame.time_relative', 'label'] + flags].copy()\n",
    "df2 = df2.head(402513)  # garantir tamanho total\n",
    "\n",
    "# Novo monitor\n",
    "def novo_monitor():\n",
    "    return EntropyMonitor(flags, window_size=600)\n",
    "\n",
    "# Inicializar monitor e resultados\n",
    "entropy_monitor = novo_monitor()\n",
    "stream_results = []\n",
    "\n",
    "# Índices das transições entre as partes\n",
    "limite_parte1 = 140544  # início da parte 2\n",
    "limite_parte2 = 261969  # início da parte 3\n",
    "\n",
    "print(\"Iniciando monitoramento de entropia com resets entre as partes...\\n\")\n",
    "\n",
    "# Loop de simulação do stream\n",
    "for i in range(402513):\n",
    "    # Reiniciar monitor nas transições\n",
    "    if i == limite_parte1 or i == limite_parte2:\n",
    "        entropy_monitor = novo_monitor()\n",
    "    \n",
    "    new_sample = df2.iloc[i].to_dict()\n",
    "    entropy_monitor.update_stream(new_sample)\n",
    "\n",
    "    entropia_atual = entropy_monitor.calculate_entropy()\n",
    "\n",
    "    stream_results.append({\n",
    "        \"Iteração\": i + 1,\n",
    "        \"frame.time_relative\": new_sample['frame.time_relative'],\n",
    "        \"label\": new_sample['label'],\n",
    "        **entropia_atual\n",
    "    })\n",
    "\n",
    "# Criar e salvar o DataFrame com entropia\n",
    "stream_df = pd.DataFrame(stream_results)\n",
    "stream_df.to_csv(\"corrigido_entropia_legitimo_malicioso.csv\", index=False)\n",
    "\n",
    "print(\"\\nMonitoramento finalizado com resets nas transições entre partes.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flags+colunas nao processdas+tempo (nao ficou bom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpeza do dataset com procesamento, dataset com aspas, conchetes e NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\['\n",
      "/tmp/ipykernel_9070/2414160219.py:1: SyntaxWarning: invalid escape sequence '\\['\n",
      "  '''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport numpy as np\\n\\n# === PASSO 1: Carregar o CSV ===\\ndf = pd.read_csv(\\'dados_legitimos.csv\\', sep=\\',\\')\\n\\n# Colunas de interesse\\nflags = [\\'tcp.flags.ack\\', \\'tcp.flags.syn\\', \\'tcp.flags.fin\\']\\nprint(flags)\\n# Criar df2 com apenas tempo e flags\\ndf2 = df[[\\'frame.time_relative\\'] + flags].copy()\\n\\n# Limitar a quantidade de amostras\\ndf2 = df2.head(140544)\\n\\n# === PASSO 1.2: Limpeza ===\\n# Remove aspas simples e colchetes em todo o DataFrame\\ndf2 = df2.replace({r\"\\'\": \"\", r\"\\\\[\": \"\", r\"\\\\]\": \"\"}, regex=True)\\n\\n# Substituir NaN e strings \\'nan\\' por 0\\ndf2 = df2.replace([\\'nan\\', np.nan], 0)\\n\\n# Converter colunas de flags para float\\ndf2[flags] = df2[flags].astype(float)\\n\\n# Verificar o shape\\nprint(df2.shape)\\n\\n# Criar monitor de entropia\\nentropy_monitor = EntropyMonitor(flags, window_size=600)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === PASSO 1: Carregar o CSV ===\n",
    "df = pd.read_csv('dados_legitimos.csv', sep=',')\n",
    "\n",
    "# Colunas de interesse\n",
    "flags = ['tcp.flags.ack', 'tcp.flags.syn', 'tcp.flags.fin']\n",
    "print(flags)\n",
    "# Criar df2 com apenas tempo e flags\n",
    "df2 = df[['frame.time_relative'] + flags].copy()\n",
    "\n",
    "# Limitar a quantidade de amostras\n",
    "df2 = df2.head(140544)\n",
    "\n",
    "# === PASSO 1.2: Limpeza ===\n",
    "# Remove aspas simples e colchetes em todo o DataFrame\n",
    "df2 = df2.replace({r\"'\": \"\", r\"\\[\": \"\", r\"\\]\": \"\"}, regex=True)\n",
    "\n",
    "# Substituir NaN e strings 'nan' por 0\n",
    "df2 = df2.replace(['nan', np.nan], 0)\n",
    "\n",
    "# Converter colunas de flags para float\n",
    "df2[flags] = df2[flags].astype(float)\n",
    "\n",
    "# Verificar o shape\n",
    "print(df2.shape)\n",
    "\n",
    "# Criar monitor de entropia\n",
    "entropy_monitor = EntropyMonitor(flags, window_size=600)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COM features no tempo originais e features selecionadas para entropia 7/05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# === PASSO 1: Carregar o CSV ===\\ndf = pd.read_csv('dataset_legitimo_malicioso.csv', sep=',')\\n\\n# Separar o que é para calcular entropia\\nflags = ['tcp.flags.ack', 'tcp.flags.syn', 'tcp.flags.fin']\\n\\n# Criar df2 com tempo + flags\\n#df2 = df[['frame.time_relative','label','tcp.len','tcp.time_delta','mqtt.len'] + flags].copy()\\ndf2 = df[['frame.time_relative', 'label'] + flags].copy()\\n\\n# Limitar a quantidade de amostras\\ndf2 = df2.head(402513)\\n\\n# Verificar o shape\\nprint(df2.shape)\\n\\n# Criar monitor de entropia só com as flags TCP\\nentropy_monitor = EntropyMonitor(flags, window_size=600)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === PASSO 1: Carregar o CSV ===\n",
    "df = pd.read_csv('dataset_legitimo_malicioso.csv', sep=',')\n",
    "\n",
    "# Separar o que é para calcular entropia\n",
    "flags = ['tcp.flags.ack', 'tcp.flags.syn', 'tcp.flags.fin']\n",
    "\n",
    "# Criar df2 com tempo + flags\n",
    "#df2 = df[['frame.time_relative','label','tcp.len','tcp.time_delta','mqtt.len'] + flags].copy()\n",
    "df2 = df[['frame.time_relative', 'label'] + flags].copy()\n",
    "\n",
    "# Limitar a quantidade de amostras\n",
    "df2 = df2.head(402513)\n",
    "\n",
    "# Verificar o shape\n",
    "print(df2.shape)\n",
    "\n",
    "# Criar monitor de entropia só com as flags TCP\n",
    "entropy_monitor = EntropyMonitor(flags, window_size=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraçao normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# === PASSO 1: Carregar o CSV ===\\ndf = pd.read_csv('dados_rotulados22.csv', sep=',')\\n\\n# Definir as colunas \\n#flags = ['tcp.srcport', 'tcp.dstport', 'tcp.len', 'tcp.flags.ack',\\n        #'tcp.flags.syn', 'tcp.flags.fin']\\n\\nflags = ['frame.time_relative','frame.time_epoch','tcp.flags.ack','tcp.flags.syn', 'tcp.flags.fin', 'tcp.flags.urg']\\n\\n# Criar um novo DataFrame apenas com essas colunas\\ndf2 = df[flags].copy()\\n\\n# Limitar a quantidade de amostras\\ndf2 = df2.head(140544)\\n\\n# Verificar o shape\\nprint(df2.shape)\\n\\n# Criar monitor de entropia para as flags TCP\\nentropy_monitor = EntropyMonitor(flags, window_size=600)  # Define o tamanho da janela deslizante.\\n#Quantidade de amostras que serão consideradas de cada vez para calcular a entropia.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# === PASSO 1: Carregar o CSV ===\n",
    "df = pd.read_csv('dados_rotulados22.csv', sep=',')\n",
    "\n",
    "# Definir as colunas \n",
    "#flags = ['tcp.srcport', 'tcp.dstport', 'tcp.len', 'tcp.flags.ack',\n",
    "        #'tcp.flags.syn', 'tcp.flags.fin']\n",
    "\n",
    "flags = ['frame.time_relative','frame.time_epoch','tcp.flags.ack','tcp.flags.syn', 'tcp.flags.fin', 'tcp.flags.urg']\n",
    "\n",
    "# Criar um novo DataFrame apenas com essas colunas\n",
    "df2 = df[flags].copy()\n",
    "\n",
    "# Limitar a quantidade de amostras\n",
    "df2 = df2.head(140544)\n",
    "\n",
    "# Verificar o shape\n",
    "print(df2.shape)\n",
    "\n",
    "# Criar monitor de entropia para as flags TCP\n",
    "entropy_monitor = EntropyMonitor(flags, window_size=600)  # Define o tamanho da janela deslizante.\n",
    "#Quantidade de amostras que serão consideradas de cada vez para calcular a entropia.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        frame.time_relative  label  tcp.flags.ack  tcp.flags.syn  \\\n",
      "0                  0.000000      0            0.0            0.0   \n",
      "1                  0.076191      0            0.0            1.0   \n",
      "2                  0.076202      0            0.0            1.0   \n",
      "3                  0.091916      0            0.0            1.0   \n",
      "4                  0.091984      0            0.0            1.0   \n",
      "...                     ...    ...            ...            ...   \n",
      "402508          1064.991926      0            0.0            1.0   \n",
      "402509          1065.028879      0            0.0            1.0   \n",
      "402510          1065.028955      0            0.0            1.0   \n",
      "402511          1065.032882      0            0.0            1.0   \n",
      "402512          1065.032892      0            0.0            1.0   \n",
      "\n",
      "        tcp.flags.fin  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n",
      "...               ...  \n",
      "402508            0.0  \n",
      "402509            0.0  \n",
      "402510            0.0  \n",
      "402511            0.0  \n",
      "402512            0.0  \n",
      "\n",
      "[402513 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processamento para flags+colunas nao processadas 7/05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# === PASSO 2: Simulação do Data Stream ===\\nnum_iterations = 402513  # Número de iterações da simulação\\n#Simula pacotes (amostras) chegando,e essas amostras sao extraidas do dataset.\\n#Cada iteração do loop simula a chegada de um novo pacote (ou seja, uma nova amostra é processada).\\nstream_results = []\\n\\nprint(\"Monitorando entropia das flags TCP...\\n\")\\n\\nfor i in range(num_iterations):\\n    # Simular novos pacotes (extraindo amostras do conjunto de dados original)\\n    #new_sample = df2.sample(n=1).iloc[0].to_dict() #A mesma amostra pode ser escolhida mais de uma vez.\\n    #Em cada iteração, uma amostra é escolhida aleatoriamente do df2\\n\\n    new_sample = df2.iloc[i].to_dict()  #Simula novos pacotes (extraindo amostras em oderm sequencial do dataset)\\n    entropy_monitor.update_stream(new_sample)\\n    \\n    # Calcular a entropia na janela atual\\n    entropia_atual = entropy_monitor.calculate_entropy()\\n    \\n    # Armazenar os resultados do stream\\n    #stream_results.append({\"Iteração\": i + 1, **entropia_atual})\\n    \\n    # Armazenar os resultados do stream (AGORA COM TEMPO REAL INCLUÍDO)\\n    stream_results.append({\\n        \"Iteração\": i + 1,\\n        \"frame.time_relative\": new_sample[\\'frame.time_relative\\'],  # adiciona o tempo original\\n        \"label\": new_sample[\\'label\\'],\\n        **entropia_atual\\n    })\\n\\n    \\'\\'\\'\\n    # Adiciona a iteração + tempos originais + entropia no registro\\n    stream_results.append({\\n        \"Iteração\": i + 1,\\n        \"frame.time_relative\": new_sample[\\'frame.time_relative\\'],\\n        \"label\": new_sample[\\'label\\'], \\n        \"tcp.len\": new_sample[\\'tcp.len\\'],  \\n        \"tcp.time_delta\": new_sample[\\'tcp.time_delta\\'], \\n        \"mqtt.len\": new_sample[\\'mqtt.len\\'], \\n        **entropia_atual\\n    })\\'\\'\\'\\n\\n    # Exibir resultados em tempo real\\n    print(f\"Iteração {i+1}: {entropia_atual}\")\\n\\n    \\'\\'\\'\\n    #Adcionado hj 21/03\\n    # Analisar a distribuição de cada flag na janela atual\\n    stream_df = pd.DataFrame(list(entropy_monitor.stream_data), columns=flags)\\n    distribuicoes = {flag: analisar_distribuicao(stream_df[flag]) for flag in flags}\\n    \\n    # Exibir informações da distribuição\\n    for flag in flags:\\n        print(f\"  Flag: {flag}\")\\n        print(f\"    - Total de amostras: {distribuicoes[flag][\\'total_amostras\\']}\")\\n        print(f\"    - Valores únicos: {distribuicoes[flag][\\'valores_unicos\\']}\")\\n        print(f\"    - Repetições: {distribuicoes[flag][\\'repeticoes\\']}\")\\n    \\'\\'\\'\\n    \\n    # Simular intervalo de tempo entre pacotes\\n    #time.sleep(0.5)  # Ajuste o tempo conforme necessário, 0.5 segundos\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# === PASSO 2: Simulação do Data Stream ===\n",
    "num_iterations = 402513  # Número de iterações da simulação\n",
    "#Simula pacotes (amostras) chegando,e essas amostras sao extraidas do dataset.\n",
    "#Cada iteração do loop simula a chegada de um novo pacote (ou seja, uma nova amostra é processada).\n",
    "stream_results = []\n",
    "\n",
    "print(\"Monitorando entropia das flags TCP...\\n\")\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Simular novos pacotes (extraindo amostras do conjunto de dados original)\n",
    "    #new_sample = df2.sample(n=1).iloc[0].to_dict() #A mesma amostra pode ser escolhida mais de uma vez.\n",
    "    #Em cada iteração, uma amostra é escolhida aleatoriamente do df2\n",
    "\n",
    "    new_sample = df2.iloc[i].to_dict()  #Simula novos pacotes (extraindo amostras em oderm sequencial do dataset)\n",
    "    entropy_monitor.update_stream(new_sample)\n",
    "    \n",
    "    # Calcular a entropia na janela atual\n",
    "    entropia_atual = entropy_monitor.calculate_entropy()\n",
    "    \n",
    "    # Armazenar os resultados do stream\n",
    "    #stream_results.append({\"Iteração\": i + 1, **entropia_atual})\n",
    "    \n",
    "    # Armazenar os resultados do stream (AGORA COM TEMPO REAL INCLUÍDO)\n",
    "    stream_results.append({\n",
    "        \"Iteração\": i + 1,\n",
    "        \"frame.time_relative\": new_sample['frame.time_relative'],  # adiciona o tempo original\n",
    "        \"label\": new_sample['label'],\n",
    "        **entropia_atual\n",
    "    })\n",
    "\n",
    "    '''\n",
    "    # Adiciona a iteração + tempos originais + entropia no registro\n",
    "    stream_results.append({\n",
    "        \"Iteração\": i + 1,\n",
    "        \"frame.time_relative\": new_sample['frame.time_relative'],\n",
    "        \"label\": new_sample['label'], \n",
    "        \"tcp.len\": new_sample['tcp.len'],  \n",
    "        \"tcp.time_delta\": new_sample['tcp.time_delta'], \n",
    "        \"mqtt.len\": new_sample['mqtt.len'], \n",
    "        **entropia_atual\n",
    "    })'''\n",
    "\n",
    "    # Exibir resultados em tempo real\n",
    "    print(f\"Iteração {i+1}: {entropia_atual}\")\n",
    "\n",
    "    '''\n",
    "    #Adcionado hj 21/03\n",
    "    # Analisar a distribuição de cada flag na janela atual\n",
    "    stream_df = pd.DataFrame(list(entropy_monitor.stream_data), columns=flags)\n",
    "    distribuicoes = {flag: analisar_distribuicao(stream_df[flag]) for flag in flags}\n",
    "    \n",
    "    # Exibir informações da distribuição\n",
    "    for flag in flags:\n",
    "        print(f\"  Flag: {flag}\")\n",
    "        print(f\"    - Total de amostras: {distribuicoes[flag]['total_amostras']}\")\n",
    "        print(f\"    - Valores únicos: {distribuicoes[flag]['valores_unicos']}\")\n",
    "        print(f\"    - Repetições: {distribuicoes[flag]['repeticoes']}\")\n",
    "    '''\n",
    "    \n",
    "    # Simular intervalo de tempo entre pacotes\n",
    "    #time.sleep(0.5)  # Ajuste o tempo conforme necessário, 0.5 segundos\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# === PASSO 3: Criar DataFrame com os resultados do Data Stream ===\\nstream_df = pd.DataFrame(stream_results)\\n\\n# Salvar os resultados em um CSV para análise posterior\\nstream_df.to_csv(\"dataset_entropia_legitimo_malicioso.csv\", index=False)\\n\\nprint(\"\\nMonitoramento finalizado! Resultados salvos em \\'dataset_entropia_legitimo_malicioso\\'\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# === PASSO 3: Criar DataFrame com os resultados do Data Stream ===\n",
    "stream_df = pd.DataFrame(stream_results)\n",
    "\n",
    "# Salvar os resultados em um CSV para análise posterior\n",
    "stream_df.to_csv(\"dataset_entropia_legitimo_malicioso.csv\", index=False)\n",
    "\n",
    "print(\"\\nMonitoramento finalizado! Resultados salvos em 'dataset_entropia_legitimo_malicioso'\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tcp.flags.urg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documentos/Mestrado/Artigo-Ciber/autocloud/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tcp.flags.urg'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m entropia_fin \u001b[38;5;241m=\u001b[39m stream_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtcp.flags.fin\u001b[39m\u001b[38;5;124m'\u001b[39m]  \n\u001b[1;32m     10\u001b[0m entropia_syn \u001b[38;5;241m=\u001b[39m stream_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtcp.flags.syn\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m entropia_urg \u001b[38;5;241m=\u001b[39m \u001b[43mstream_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtcp.flags.urg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m entropia_delta \u001b[38;5;241m=\u001b[39m stream_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtcp.time_delta\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Criar o gráfico\u001b[39;00m\n",
      "File \u001b[0;32m~/Documentos/Mestrado/Artigo-Ciber/autocloud/venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Documentos/Mestrado/Artigo-Ciber/autocloud/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tcp.flags.urg'"
     ]
    }
   ],
   "source": [
    "# === PASSO 4: Criar Gráfico ===\n",
    "\n",
    "# Definir o número de amostras desejadas\n",
    "#num_iterations = 880000  # Altere esse valor para controlar quantas amostras serão plotadas\n",
    "\n",
    "# Preparar os dados para o gráfico\n",
    "iterations = stream_df['Iteração']\n",
    "entropia_ack = stream_df['tcp.flags.ack']\n",
    "entropia_fin = stream_df['tcp.flags.fin']  \n",
    "entropia_syn = stream_df['tcp.flags.syn']\n",
    "entropia_urg = stream_df['tcp.flags.urg']\n",
    "entropia_delta = stream_df['tcp.time_delta']\n",
    "\n",
    "# Criar o gráfico\n",
    "plt.figure(figsize=(10, 6))  # Tamanho do gráfico\n",
    "plt.plot(iterations, entropia_ack, label='tcp.flags.ack', marker='o')\n",
    "plt.plot(iterations, entropia_fin, label='tcp.flags.fin', marker='X')\n",
    "plt.plot(iterations, entropia_syn, label='tcp.flags.syn', marker='^')\n",
    "plt.plot(iterations, entropia_urg, label='tcp.flags.urg', marker='d')\n",
    "plt.plot(iterations, entropia_delta, label='tcp.time_delta', marker='+')\n",
    "\n",
    "\n",
    "# Adicionar título e rótulos\n",
    "plt.title(f'Entropia das Flags TCP ao Longo das Iterações (Primeiras {num_iterations}Amostras)')\n",
    "plt.xlabel('Iteração')\n",
    "plt.ylabel('Entropia')\n",
    "plt.legend()  # Mostrar legenda\n",
    "plt.grid(True)  # Adicionar grid ao gráfico\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
